{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# OHNN: ONE HOT NEURAL NETWORK\n",
    "\n",
    "We present here One Hot Neural Network\n",
    "\n",
    "...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import fede_code.torch_functions as tof\n",
    "import fede_code.objects as obj\n",
    "import fede_code.model_trainer as mt\n",
    "import fede_code.graphics_functions as grafun\n",
    "from torch.optim import AdamW, RMSprop\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from fede_code.loss_functions import penalizedLoss\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ADULT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age          workclass  fnlwgt   education  educational-num  \\\n",
      "0   39          State-gov   77516   Bachelors               13   \n",
      "1   50   Self-emp-not-inc   83311   Bachelors               13   \n",
      "2   38            Private  215646     HS-grad                9   \n",
      "3   53            Private  234721        11th                7   \n",
      "4   28            Private  338409   Bachelors               13   \n",
      "\n",
      "        marital-status          occupation    relationship    race   gender  \\\n",
      "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
      "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
      "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
      "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
      "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week  native-country  target  \n",
      "0          2174             0              40   United-States       0  \n",
      "1             0             0              13   United-States       0  \n",
      "2             0             0              40   United-States       0  \n",
      "3             0             0              40   United-States       0  \n",
      "4             0             0              40            Cuba       0  \n"
     ]
    }
   ],
   "source": [
    "data_path = 'C:\\\\Users\\\\drikb\\\\Desktop\\\\CRISP\\\\XAI project\\\\nn\\\\data\\\\adult.csv'\n",
    "\n",
    "headers = ['age', 'workclass', 'fnlwgt', 'education', 'educational-num', 'marital-status', 'occupation',\n",
    "           'relationship', 'race', 'gender', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
    "           'target']\n",
    "\n",
    "df_adult = pd.read_csv(data_path)\n",
    "\n",
    "print(df_adult.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_adult.columns:\n",
    "    if df_adult[col].dtype == 'object':\n",
    "        df_adult[col] = pd.Categorical(df_adult[col])\n",
    "        df_adult[col] = df_adult[col].cat.codes\n",
    "df_adult = df_adult.astype(float)\n",
    "\n",
    "x = df_adult.drop(columns=['target'])\n",
    "y = df_adult['target'].values\n",
    "\n",
    "adult_x_train, adult_x_test, adult_y_train, adult_y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#standardize the dataset\n",
    "sc = StandardScaler()\n",
    "sc.fit(adult_x_train)\n",
    "adult_x_train = sc.transform(adult_x_train)\n",
    "adult_x_test = sc.transform(adult_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_train_set = mt.TrainDataset(torch.tensor(adult_x_train, dtype=torch.float32),\n",
    "                     torch.tensor(adult_y_train, dtype=torch.float32))\n",
    "\n",
    "adult_test_set = mt.TrainDataset(torch.tensor(adult_x_test, dtype=torch.float32),\n",
    "                           torch.tensor(adult_y_test, dtype=torch.float32))\n",
    "\n",
    "adult_train_loader = DataLoader(adult_train_set, batch_size=32, shuffle=True)\n",
    "adult_test_loader = DataLoader(adult_test_set, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PREDICTIVE MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 on 0 score SVM: 0.4601661027376192\n",
      "f1 on 1 score SVM: 0.8922453490513907\n",
      "accuracy SVM: 0.8203500870099294\n"
     ]
    }
   ],
   "source": [
    "svm_clf = svm.SVC(kernel='linear')\n",
    "svm_clf.fit(adult_x_train,adult_y_train)\n",
    "predicted_svm = svm_clf.predict(adult_x_test)\n",
    "f1_0_svm, f1_1_svm = f1_score(adult_y_test,predicted_svm,\n",
    "                                 average = None,\n",
    "                                zero_division = 0,\n",
    "                                labels = np.array([0, 1]))\n",
    "accuracy_svm = accuracy_score(adult_y_test, predicted_svm)\n",
    "\n",
    "print('f1 on 0 score SVM:', f1_1_svm)\n",
    "print('f1 on 1 score SVM:', f1_0_svm)\n",
    "print('accuracy SVM:', accuracy_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the dataset of predictions to perform explanation\n",
    "pred_set_svm = mt.TrainDataset(torch.tensor(adult_x_test, dtype=torch.float32),\n",
    "                               torch.tensor(predicted_svm, dtype=torch.float32))\n",
    "\n",
    "pred_loader_svm = DataLoader(pred_set_svm, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Deep Neural Network (DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class deepNN(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(deepNN, self).__init__()\n",
    "        self.linear_1 = nn.Linear(in_features, 128)\n",
    "        self.act_1 = nn.LeakyReLU()\n",
    "        self.linear_2 = nn.Linear(128, 64)\n",
    "        self.act_2 = nn.LeakyReLU()\n",
    "        self.linear_out = nn.Linear(64, 1)\n",
    "        self.final_act = nn.Sigmoid()\n",
    "        self.num_rules = 0 #<--- this allows to use model trainer, must be fixed\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear_1(x)\n",
    "        x = self.act_1(x)\n",
    "        x = self.linear_2(x)\n",
    "        x = self.act_2(x)\n",
    "        x = self.linear_out(x)\n",
    "        x = self.final_act(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d513d07904d4c67904c8e35a7a88878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dnn = deepNN(in_features = 14)\n",
    "\n",
    "loss_fn = penalizedLoss(loss_fn = nn.BCELoss(reduction='sum'), #<--- reduction='sum' is mandatory\n",
    "                        parameters = dnn.parameters(),\n",
    "                        l1_lambda = 0.5,\n",
    "                        l2_lambda = 0.5)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print('GPU')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('CPU')\n",
    "\n",
    "\n",
    "trainer = mt.modelTrainer(model=dnn,\n",
    "                          loss_fn=loss_fn,\n",
    "                          optimizer=AdamW)\n",
    "\n",
    "trainer.train_model(train_data_loader=adult_train_loader,\n",
    "                    num_epochs=100,\n",
    "                    device=device,\n",
    "                    learning_rate=1e-5,\n",
    "                    display_log='epoch',\n",
    "                   store_weights_history=False,\n",
    "                   store_weights_grad=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0133433009f453db0f1daea796cf372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/306 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.32505376195697705\n",
      "Accuracy: 0.8490121813901116\n",
      "F1 score on label 0: 0.9021680135965053\n",
      "F1 score on label 1: 0.6297476101422543\n"
     ]
    }
   ],
   "source": [
    "loss_dnn, accuracy_dnn, f1_0_dnn, f1_1_dnn = trainer.eval_model(adult_test_loader, device=device)\n",
    "print(f'Average loss: {loss_dnn}')\n",
    "print(f'Accuracy: {accuracy_dnn}')\n",
    "print(f'F1 score on label 0: {f1_0_dnn}')\n",
    "print(f'F1 score on label 1: {f1_1_dnn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a357bfa308994779881ec1daed1367cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/306 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_dnn = trainer.predict(adult_test_loader, device=device, prob=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the dataset of predictions to perform explanation\n",
    "pred_set_dnn = mt.TrainDataset(torch.tensor(adult_x_test, dtype=torch.float32),\n",
    "                               torch.tensor(predicted_dnn.detach().numpy(), dtype=torch.float32))\n",
    "\n",
    "pred_loader_dnn = DataLoader(pred_set_dnn, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. EXPLANATION MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 LOGISTIC REGRESSION (LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()\n",
    "\n",
    "log_reg_svm = log_reg.fit(adult_x_test, predicted_svm)\n",
    "log_reg_dnn = log_reg.fit(adult_x_test, predicted_dnn)\n",
    "\n",
    "log_reg_pred_svm = log_reg_svm.predict(adult_x_test)\n",
    "log_reg_pred_dnn = log_reg_dnn.predict(adult_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation accuracy on SVM: 0.9215886989456444\n",
      "Explanation f1 of 0 on SVM: 0.954861520329994\n",
      "Explanation f1 of 1 on SVM: 0.7017133956386293\n",
      "Explanation accuracy on DNN: 0.921179240454499\n",
      "Explanation f1 of 0 on DNN: 0.9519890260631001\n",
      "Explanation f1 of 1 on DNN: 0.78\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "log_reg_accuracy_svm = (log_reg_pred_svm == predicted_svm).sum()/len(predicted_svm)\n",
    "log_reg_f1_0_svm, log_reg_f1_1_svm = f1_score(predicted_svm,log_reg_pred_svm,\n",
    "                                              average = None,\n",
    "                                              zero_division = 0,\n",
    "                                              labels = np.array([0, 1]))\n",
    "\n",
    "# DNN\n",
    "log_reg_accuracy_dnn = (log_reg_pred_dnn == predicted_dnn.detach().numpy()).sum()/len(predicted_dnn)\n",
    "log_reg_f1_0_dnn, log_reg_f1_1_dnn = f1_score(predicted_dnn,log_reg_pred_dnn,\n",
    "                                              average = None,\n",
    "                                              zero_division = 0,\n",
    "                                              labels = np.array([0, 1]))\n",
    "\n",
    "print('Explanation accuracy on SVM:', log_reg_accuracy_svm)\n",
    "print('Explanation f1 of 0 on SVM:', log_reg_f1_0_svm)\n",
    "print('Explanation f1 of 1 on SVM:', log_reg_f1_1_svm)\n",
    "\n",
    "print('Explanation accuracy on DNN:', log_reg_accuracy_dnn)\n",
    "print('Explanation f1 of 0 on DNN:', log_reg_f1_0_dnn)\n",
    "print('Explanation f1 of 1 on DNN:', log_reg_f1_1_dnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 DECISION TREE (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(criterion='gini',\n",
    "                            max_depth = 4,\n",
    "                            max_leaf_nodes = 16)\n",
    "\n",
    "dt_svm = dt.fit(adult_x_test, predicted_svm)\n",
    "dt_dnn = dt.fit(adult_x_test, predicted_dnn)\n",
    "\n",
    "dt_pred_svm = dt_svm.predict(adult_x_test)\n",
    "dt_pred_dnn = dt_dnn.predict(adult_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation accuracy on SVM: 0.9068481932644078\n",
      "Explanation f1 of 0 on SVM: 0.9465711601690934\n",
      "Explanation f1 of 1 on SVM: 0.6368715083798884\n",
      "Explanation accuracy on DNN: 0.9404237895383355\n",
      "Explanation f1 of 0 on DNN: 0.9638509316770186\n",
      "Explanation f1 of 1 on DNN: 0.8307155322862129\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "dt_accuracy_svm = (dt_pred_svm == predicted_svm).sum()/len(predicted_svm)\n",
    "dt_f1_0_svm, dt_f1_1_svm = f1_score(predicted_svm,dt_pred_svm,\n",
    "                                              average = None,\n",
    "                                              zero_division = 0,\n",
    "                                              labels = np.array([0, 1]))\n",
    "\n",
    "# DNN\n",
    "dt_accuracy_dnn = (dt_pred_dnn == predicted_dnn.detach().numpy()).sum()/len(predicted_dnn)\n",
    "dt_f1_0_dnn, dt_f1_1_dnn = f1_score(predicted_dnn,dt_pred_dnn,\n",
    "                                              average = None,\n",
    "                                              zero_division = 0,\n",
    "                                              labels = np.array([0, 1]))\n",
    "\n",
    "print('Explanation accuracy on SVM:', dt_accuracy_svm)\n",
    "print('Explanation f1 of 0 on SVM:', dt_f1_0_svm)\n",
    "print('Explanation f1 of 1 on SVM:', dt_f1_1_svm)\n",
    "\n",
    "print('Explanation accuracy on DNN:', dt_accuracy_dnn)\n",
    "print('Explanation f1 of 0 on DNN:', dt_f1_0_dnn)\n",
    "print('Explanation f1 of 1 on DNN:', dt_f1_1_dnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONE HOT NEURAL NETWORK (OHNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf886dd0e9de4328a1d26ff219337d14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ohnn_svm = obj.oneHotRuleNN(input_size=14,\n",
    "                        num_neurons=4, #tree max depth\n",
    "                        num_rules=16, #tree max leaves\n",
    "                        final_activation=nn.Sigmoid,\n",
    "                        rule_weight_constraint=tof.getMax,\n",
    "                        out_weight_constraint=None,\n",
    "                        rule_bias=True,\n",
    "                        neuron_bias=False,\n",
    "                        rule_activation=nn.Sigmoid,\n",
    "                        neuron_activation=None,\n",
    "                        out_bias=False,\n",
    "                        force_positive_hidden_init=False,\n",
    "                        force_positive_out_init=False,\n",
    "                        dtype=torch.float32)\n",
    "\n",
    "#loss_fn = nn.BCELoss(reduction='sum')\n",
    "loss_fn = penalizedLoss(loss_fn = nn.BCELoss(reduction='sum'), #<--- reduction='sum' is mandatory\n",
    "                        parameters = ohnn_svm.rule_weight.linear.weight,\n",
    "                        l1_lambda = 0.3,\n",
    "                        l2_lambda = 0.0)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print('GPU')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('CPU')\n",
    "\n",
    "\n",
    "trainer_svm = mt.modelTrainer(model=ohnn_svm,\n",
    "                          loss_fn=loss_fn,\n",
    "                          optimizer=AdamW)\n",
    "\n",
    "trainer_svm.train_model(train_data_loader=pred_loader_svm,\n",
    "                    num_epochs=100,\n",
    "                    device=device,\n",
    "                    learning_rate=1e-3,\n",
    "                    display_log='epoch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd1e638e25a4fdd91b44cd04458eed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ohnn_dnn = obj.oneHotRuleNN(input_size=14,\n",
    "                        num_neurons=4, #tree max depth\n",
    "                        num_rules=16, #tree max leaves\n",
    "                        final_activation=nn.Sigmoid,\n",
    "                        rule_weight_constraint=tof.getMax,\n",
    "                        out_weight_constraint=None,\n",
    "                        rule_bias=True,\n",
    "                        neuron_bias=False,\n",
    "                        rule_activation=nn.Sigmoid,\n",
    "                        neuron_activation=None,\n",
    "                        out_bias=False,\n",
    "                        force_positive_hidden_init=False,\n",
    "                        force_positive_out_init=False,\n",
    "                        dtype=torch.float32)\n",
    "\n",
    "#loss_fn = nn.BCELoss(reduction='sum')\n",
    "loss_fn = penalizedLoss(loss_fn = nn.BCELoss(reduction='sum'), #<--- reduction='sum' is mandatory\n",
    "                        parameters = ohnn_dnn.rule_weight.linear.weight,\n",
    "                        l1_lambda = 0.3,\n",
    "                        l2_lambda = 0.0)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print('GPU')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('CPU')\n",
    "\n",
    "\n",
    "trainer_dnn = mt.modelTrainer(model=ohnn_dnn,\n",
    "                          loss_fn=loss_fn,\n",
    "                          optimizer=AdamW)\n",
    "\n",
    "trainer_dnn.train_model(train_data_loader=pred_loader_dnn,\n",
    "                    num_epochs=100,\n",
    "                    device=device,\n",
    "                    learning_rate=1e-3,\n",
    "                    display_log='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "906cc47fe0514dfdb15bbabfcab4b1a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/611 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af13a6572f224d958142bd5d494e4087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/611 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation accuracy on SVM: 0.9766608660047088\n",
      "Explanation f1 of 0 on SVM: 0.9867155930149829\n",
      "Explanation f1 of 1 on SVM: 0.6494375600758586\n",
      "Explanation accuracy on DNN: 0.9399119664244038\n",
      "Explanation f1 of 0 on DNN: 0.9622440426442823\n",
      "Explanation f1 of 1 on DNN: 0.7596399963012087\n"
     ]
    }
   ],
   "source": [
    "ohnn_loss_svm, ohnn_accuracy_svm, ohnn_f1_0_svm, ohnn_f1_1_svm = trainer_svm.eval_model(pred_loader_svm, device='cpu')\n",
    "ohnn_loss_dnn, ohnn_accuracy_dnn, ohnn_f1_0_dnn, ohnn_f1_1_dnn = trainer_dnn.eval_model(pred_loader_dnn, device='cpu')\n",
    "\n",
    "print('Explanation accuracy on SVM:', ohnn_accuracy_svm)\n",
    "print('Explanation f1 of 0 on SVM:', ohnn_f1_0_svm)\n",
    "print('Explanation f1 of 1 on SVM:', ohnn_f1_1_svm)\n",
    "\n",
    "print('Explanation accuracy on DNN:', ohnn_accuracy_dnn)\n",
    "print('Explanation f1 of 0 on DNN:', ohnn_f1_0_dnn)\n",
    "print('Explanation f1 of 1 on DNN:', ohnn_f1_1_dnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {\n",
    "    'Logistic regression': {\n",
    "        'SVM': {'Accuracy': log_reg_accuracy_svm, 'F1 Score (Class 0)': log_reg_f1_0_svm, 'F1 Score (Class 1)': log_reg_f1_1_svm},\n",
    "        'DNN': {'Accuracy': log_reg_accuracy_dnn, 'F1 Score (Class 0)': log_reg_f1_0_dnn, 'F1 Score (Class 1)': log_reg_f1_1_dnn},\n",
    "    },\n",
    "    'Decision tree': {\n",
    "        'SVM': {'Accuracy': dt_accuracy_svm, 'F1 Score (Class 0)': dt_f1_0_svm, 'F1 Score (Class 1)': dt_f1_1_svm},\n",
    "        'DNN': {'Accuracy': dt_accuracy_dnn, 'F1 Score (Class 0)': dt_f1_0_dnn, 'F1 Score (Class 1)': dt_f1_1_dnn},\n",
    "    },\n",
    "    'OHNN': {\n",
    "        'SVM': {'Accuracy': ohnn_accuracy_svm, 'F1 Score (Class 0)': ohnn_f1_0_svm, 'F1 Score (Class 1)': ohnn_f1_1_svm},\n",
    "        'DNN': {'Accuracy': ohnn_accuracy_dnn, 'F1 Score (Class 0)': ohnn_f1_0_dnn, 'F1 Score (Class 1)': ohnn_f1_1_dnn},\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-----------------------+----------+--------------------+--------------------+\n",
      "|        Model        | Explained Predictions | Accuracy | F1 Score (Class 0) | F1 Score (Class 1) |\n",
      "+---------------------+-----------------------+----------+--------------------+--------------------+\n",
      "| Logistic regression |          SVM          |  0.9216  |       0.9549       |       0.7017       |\n",
      "| Logistic regression |          DNN          |  0.9212  |       0.952        |        0.78        |\n",
      "|    Decision tree    |          SVM          |  0.9068  |       0.9466       |       0.6369       |\n",
      "|    Decision tree    |          DNN          |  0.9404  |       0.9639       |       0.8307       |\n",
      "|        OHNN         |          SVM          |  0.9767  |       0.9867       |       0.6494       |\n",
      "|        OHNN         |          DNN          |  0.9399  |       0.9622       |       0.7596       |\n",
      "+---------------------+-----------------------+----------+--------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "df_scores = pd.DataFrame.from_dict({(i, j): scores[i][j] \n",
    "                              for i in scores.keys() \n",
    "                              for j in scores[i].keys()}, orient='index')\n",
    "\n",
    "# Rename index and columns\n",
    "df_scores.index.names = ['Model', 'Explained Predictions']\n",
    "df_scores.reset_index(inplace=True)\n",
    "\n",
    "# Format the DataFrame to round the values to a certain number of decimal places (e.g., 2)\n",
    "df_scores = df_scores.round(4)\n",
    "\n",
    "# Print the table using tabulate\n",
    "table = tabulate(df_scores, headers='keys', tablefmt='pretty', showindex=False)\n",
    "\n",
    "print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
